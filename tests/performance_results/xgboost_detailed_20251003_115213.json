{
  "summary": {
    "model_name": "xgboost",
    "metrics": {
      "accuracy": 0.4393939393939394,
      "precision_macro": 0.3525641025641026,
      "recall_macro": 0.3356516290726817,
      "f1_macro": 0.32994579945799457,
      "precision_weighted": 0.3991841491841492,
      "recall_weighted": 0.43939393939393934,
      "f1_weighted": 0.40622690317812266
    },
    "thresholds": {
      "min_f1_macro": 0.6,
      "min_f1_weighted": 0.6,
      "min_accuracy": 0.65,
      "min_precision_macro": 0.6,
      "min_recall_macro": 0.6
    },
    "passed": false,
    "timestamp": "2025-10-03T11:52:12.981351"
  },
  "classification_report": {
    "candidate": {
      "precision": 0.5,
      "recall": 0.6714285714285714,
      "f1-score": 0.573170731707317,
      "support": 70.0
    },
    "confirmed": {
      "precision": 0.25,
      "recall": 0.125,
      "f1-score": 0.16666666666666666,
      "support": 24.0
    },
    "false_positive": {
      "precision": 0.3076923076923077,
      "recall": 0.21052631578947367,
      "f1-score": 0.25,
      "support": 38.0
    },
    "accuracy": 0.4393939393939394,
    "macro avg": {
      "precision": 0.3525641025641026,
      "recall": 0.3356516290726817,
      "f1-score": 0.32994579945799457,
      "support": 132.0
    },
    "weighted avg": {
      "precision": 0.3991841491841492,
      "recall": 0.43939393939393934,
      "f1-score": 0.40622690317812266,
      "support": 132.0
    }
  },
  "confusion_matrix": [
    [
      47,
      7,
      16
    ],
    [
      19,
      3,
      2
    ],
    [
      28,
      2,
      8
    ]
  ],
  "class_names": [
    "candidate",
    "confirmed",
    "false_positive"
  ],
  "test_config": {
    "n_samples": 500,
    "test_size": 0.3,
    "random_state": 42,
    "models_to_test": [
      "random_forest",
      "xgboost"
    ]
  },
  "recommendations": [
    "F1 score below threshold. Consider: 1) Increasing dataset size, 2) Feature engineering, 3) Hyperparameter tuning, 4) Class balancing techniques",
    "Accuracy below threshold. Consider: 1) Model complexity adjustments, 2) Cross-validation for better generalization, 3) Ensemble methods"
  ]
}